{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../', '/Users/federicosiciliano/Desktop/Py_utils/torch_utils/ntb', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python38.zip', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/Users/federicosiciliano/Library/Python/3.8/lib/python/site-packages', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "project_folder = \"../\"\n",
    "sys.path.insert(0, project_folder)\n",
    "print(sys.path) # view the path and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils, exp_utils, torch_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = exp_utils.cfg.load_configuration(\"config_nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__exp__': {'name': 'prova',\n",
       "  'project_folder': '../',\n",
       "  'key_len': 16,\n",
       "  'key_prefix': '',\n",
       "  '__imports__': ['torchvision'],\n",
       "  '__nosave__': {'model.loader_params.num_workers': None,\n",
       "   'model.trainer_params.accelerator': None,\n",
       "   'model.trainer_params.enable_checkpointing': None,\n",
       "   'model.trainer_params.logger': None,\n",
       "   'model.trainer_params.callbacks.1.ModelCheckpoint.dirpath': None,\n",
       "   'model.trainer_params.callbacks.1.ModelCheckpoint.filename': None}},\n",
       " 'data': {'name': 'MNIST',\n",
       "  'source': 'torchvision',\n",
       "  'merge_before_split': False,\n",
       "  'split_keys': {'train_x': ['train_x', 'val_x'],\n",
       "   'train_y': ['train_y', 'val_y']},\n",
       "  'train_sizes': [100, 100],\n",
       "  'test_sizes': [0.2],\n",
       "  'split_random_state': 21094,\n",
       "  'one_hot_encode': True,\n",
       "  'scaling': 'MinMax'},\n",
       " 'model': {'name': 'resnet18',\n",
       "  'num_parameters': [1, 10, 100, 200, 1000],\n",
       "  'torchvision_params': {'weights': None},\n",
       "  'optimizer': {'name': 'Adam', 'params': {'lr': 0.1, 'weight_decay': 0.0005}},\n",
       "  'loss': 'CrossEntropyLoss',\n",
       "  'loader_params': {'batch_size': 256, 'num_workers': 1},\n",
       "  'trainer_params': {'max_epochs': 1,\n",
       "   'callbacks': [{'EarlyStopping': {'monitor': 'val_loss',\n",
       "      'mode': 'min',\n",
       "      'patience': 1}},\n",
       "    {'ModelCheckpoint': {'save_top_k': 1,\n",
       "      'save_last': True,\n",
       "      'monitor': 'val_loss',\n",
       "      'mode': 'min',\n",
       "      'dirpath': '..//out/models/prova/',\n",
       "      'filename': 'best'}}],\n",
       "   'accelerator': 'cpu',\n",
       "   'enable_checkpointing': True,\n",
       "   'logger': {'name': 'CSVLogger',\n",
       "    'params': {'save_dir': '..//out/log/prova/'}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_utils.data.load_data(**cfg[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = torch_utils.preparation.prepare_data_loaders(data, cfg[\"model\"][\"loader_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"model\"][\"in_channels\"] = data[\"train_x\"].shape[1]\n",
    "cfg[\"model\"][\"out_features\"] = data[\"train_y\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_module = torch_utils.model.get_torchvision_model(**cfg[\"model\"])\n",
    "#ricreare con num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_found, experiment_id = exp_utils.exp.get_experiment_id(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True NbrnTP3fAbnFbmOH\n"
     ]
    }
   ],
   "source": [
    "print(exp_found, experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if exp_found: continue\n",
    "# else:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: EarlyStopping not recognized for adding experiment_id\n"
     ]
    }
   ],
   "source": [
    "#Set experiment_id in trainer_params\n",
    "trainer_params = torch_utils.preparation.prepare_experiment_id(cfg[\"model\"][\"trainer_params\"], experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_params[\"callbacks\"] = torch_utils.preparation.prepare_callbacks(trainer_params)\n",
    "trainer_params[\"logger\"] = torch_utils.preparation.prepare_logger(cfg[\"model\"][\"trainer_params\"])\n",
    "trainer = torch_utils.preparation.prepare_trainer(**trainer_params)\n",
    "\n",
    "# callbacks = torch_utils.preparation.prepare_callbacks(cfg[\"model\"][\"trainer_params\"])\n",
    "# logger = torch_utils.preparation.prepare_logger(cfg[\"model\"][\"trainer_params\"])\n",
    "# already_defined = [\"callbacks\",\"logger\"]\n",
    "# trainer = torch_utils.preparation.prepare_trainer(**{k:cfg[\"model\"][\"trainer_params\"][k] for k in cfg[\"model\"][\"trainer_params\"] if k not in already_defined}, callbacks=callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch_utils.preparation.prepare_loss(cfg[\"model\"][\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch_utils.preparation.prepare_optimizer(**cfg[\"model\"][\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "model = torch_utils.process.create_model(main_module, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | main_module | ResNet           | 11.2 M\n",
      "1 | loss        | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.701    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90f30d6183a459b97decb1878cf540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicosiciliano/Library/Python/3.8/lib/python/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/federicosiciliano/Library/Python/3.8/lib/python/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/federicosiciliano/Library/Python/3.8/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637e6d99a14c467c826c6b283366ccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b2f01dca0483099931e4ee92476a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_utils.process.train_model(trainer, model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicosiciliano/Library/Python/3.8/lib/python/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ec88f9881f46e5ab2398acc472a546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3384501075968.0      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3384501075968.0     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_utils.process.test_model(trainer, model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ModelCheckpoint is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/federicosiciliano/Desktop/Py_utils/torch_utils/ntb/try_torch.ipynb Cella 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/federicosiciliano/Desktop/Py_utils/torch_utils/ntb/try_torch.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m exp_utils\u001b[39m.\u001b[39;49mexp\u001b[39m.\u001b[39;49msave_experiment(cfg)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/exp_utils/exp.py:184\u001b[0m, in \u001b[0;36msave_experiment\u001b[0;34m(cfg, exp_cfg, compute_exp_id)\u001b[0m\n\u001b[1;32m    181\u001b[0m cfg, exp_cfg \u001b[39m=\u001b[39m remove_nosave_keys(cfg, exp_cfg)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m compute_exp_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mexperiment_id\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exp_cfg:\n\u001b[0;32m--> 184\u001b[0m \tget_set_experiment_id(cfg, exp_cfg, nosave_removed \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m save_hashing(cfg, exp_cfg)\n\u001b[1;32m    188\u001b[0m save_config(cfg, exp_cfg)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/exp_utils/exp.py:116\u001b[0m, in \u001b[0;36mget_set_experiment_id\u001b[0;34m(cfg, exp_cfg, nosave_removed)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_set_experiment_id\u001b[39m(cfg, exp_cfg,nosave_removed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m): \u001b[39m#parameter to overwrite experiment_id?\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \texp_found, exp_id \u001b[39m=\u001b[39m get_experiment_id(cfg, exp_cfg,nosave_removed) \u001b[39m#if \"experiment_id\" not in exp_cfg else True,exp_cfg[\"experiment_id\"]\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \tset_experiment_id(exp_cfg, exp_id)\n\u001b[1;32m    118\u001b[0m \t\u001b[39mreturn\u001b[39;00m exp_found, exp_id\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/exp_utils/exp.py:86\u001b[0m, in \u001b[0;36mget_experiment_id\u001b[0;34m(cfg, exp_cfg, nosave_removed)\u001b[0m\n\u001b[1;32m     83\u001b[0m \tcfg, exp_cfg \u001b[39m=\u001b[39m remove_nosave_keys(cfg, exp_cfg)\n\u001b[1;32m     85\u001b[0m \u001b[39m#This could be made better using binary search in the file, if kept sorted, instead of loading the whole dict\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m cfg_hash \u001b[39m=\u001b[39m get_set_hashing(cfg,exp_cfg)\n\u001b[1;32m     88\u001b[0m exp_id \u001b[39m=\u001b[39m all_exps\u001b[39m.\u001b[39mget(cfg_hash,\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m \u001b[39m#print(exp_id)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/exp_utils/exp.py:170\u001b[0m, in \u001b[0;36mget_set_hashing\u001b[0;34m(cfg, exp_cfg)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_set_hashing\u001b[39m(cfg,exp_cfg):\n\u001b[0;32m--> 170\u001b[0m \texp_cfg[\u001b[39m\"\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hash_config(cfg)\n\u001b[1;32m    171\u001b[0m \t\u001b[39mreturn\u001b[39;00m exp_cfg[\u001b[39m\"\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/exp_utils/exp.py:33\u001b[0m, in \u001b[0;36mhash_config\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhash_config\u001b[39m(cfg):\n\u001b[0;32m---> 33\u001b[0m \t\u001b[39mreturn\u001b[39;00m hashlib\u001b[39m.\u001b[39mmd5(json\u001b[39m.\u001b[39;49mdumps(cfg, sort_keys\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mencode())\u001b[39m.\u001b[39mhexdigest()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    235\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[1;32m    236\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    237\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[1;32m    238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ModelCheckpoint is not JSON serializable"
     ]
    }
   ],
   "source": [
    "exp_utils.exp.save_experiment(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
